# Configuration pour le modèle Text_Base_fr_4GB_v0 - Tâche XNLI-HF
# Paramètres du modèle
model_type=pantagruel
model_name=Text_Base_fr_4GB_v0

# Chemin vers le modèle - utilise la variable d'environnement MODEL_NAME si définie
# Le modèle est maintenant directement dans le dossier principal
if [ ! -z "$MODEL_NAME" ]; then
    model_name_or_path=flue/pretrained_models/$MODEL_NAME
else
    model_name_or_path=flue/pretrained_models/Text_Base_fr_4GB_v0
fi

# Paramètres d'entraînement - adaptés pour PantagruelModel
batch_size=4
lr=0.000005
epochs=5
dropout=0.1
weight_decay=0.01
warmup_steps=500
gradient_accumulation_steps=2

# Stratégies d'évaluation et sauvegarde
eval_strategy=epoch
save_strategy=epoch
save_steps=1000

# Paramètres des données
data_dir=flue/data/xnli/processed-csv
train_file=flue/data/xnli/processed-csv/train.csv
validation_file=flue/data/xnli/processed-csv/valid.csv
test_file=flue/data/xnli/processed-csv/test.csv

# Paramètres de séquence
max_seq_length=512

# Répertoire de sortie
output_dir=flue/experiments/Text_Base_fr_4GB_v0/xnli_hf_results

# Paramètres de logging
logging_steps=100
logging_strategy=steps

# Paramètres d'optimisation
adam_epsilon=1e-8
max_grad_norm=1.0

# Paramètres de reproductibilité
seed=42
